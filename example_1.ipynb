{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Preparation With Basic Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we're going to to take the simplest approach to combining all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname_train = 'data/train.csv'\n",
    "fname_test = 'data/test.csv'\n",
    "fname_macro = 'data/macro.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(fname_train)\n",
    "df_test = pd.read_csv(fname_test)\n",
    "df_macro = pd.read_csv(fname_macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull in all the data, combine it, take a look at some stats and do very basic preparation (with no real feature engineering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30471, 391)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>...</th>\n",
       "      <th>provision_retail_space_modern_sqm</th>\n",
       "      <th>turnover_catering_per_cap</th>\n",
       "      <th>theaters_viewers_per_1000_cap</th>\n",
       "      <th>seats_theather_rfmin_per_100000_cap</th>\n",
       "      <th>museum_visitis_per_100_cap</th>\n",
       "      <th>bandwidth_sports</th>\n",
       "      <th>population_reg_sports_share</th>\n",
       "      <th>students_reg_sports_share</th>\n",
       "      <th>apartment_build</th>\n",
       "      <th>apartment_fund_sqm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-08-20</td>\n",
       "      <td>43</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>269768.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.12</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>230310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-08-23</td>\n",
       "      <td>34</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>269768.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.12</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>230310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-08-27</td>\n",
       "      <td>43</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>269768.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.12</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>230310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>89</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>269768.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.12</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>230310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>77</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>269768.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.12</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>230310.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   timestamp  full_sq  life_sq  floor  max_floor  material  build_year  \\\n",
       "0   1  2011-08-20       43     27.0    4.0        NaN       NaN         NaN   \n",
       "1   2  2011-08-23       34     19.0    3.0        NaN       NaN         NaN   \n",
       "2   3  2011-08-27       43     29.0    2.0        NaN       NaN         NaN   \n",
       "3   4  2011-09-01       89     50.0    9.0        NaN       NaN         NaN   \n",
       "4   5  2011-09-05       77     77.0    4.0        NaN       NaN         NaN   \n",
       "\n",
       "   num_room  kitch_sq         ...          provision_retail_space_modern_sqm  \\\n",
       "0       NaN       NaN         ...                                      271.0   \n",
       "1       NaN       NaN         ...                                      271.0   \n",
       "2       NaN       NaN         ...                                      271.0   \n",
       "3       NaN       NaN         ...                                      271.0   \n",
       "4       NaN       NaN         ...                                      271.0   \n",
       "\n",
       "  turnover_catering_per_cap theaters_viewers_per_1000_cap  \\\n",
       "0                    6943.0                         565.0   \n",
       "1                    6943.0                         565.0   \n",
       "2                    6943.0                         565.0   \n",
       "3                    6943.0                         565.0   \n",
       "4                    6943.0                         565.0   \n",
       "\n",
       "   seats_theather_rfmin_per_100000_cap  museum_visitis_per_100_cap  \\\n",
       "0                              0.45356                      1240.0   \n",
       "1                              0.45356                      1240.0   \n",
       "2                              0.45356                      1240.0   \n",
       "3                              0.45356                      1240.0   \n",
       "4                              0.45356                      1240.0   \n",
       "\n",
       "   bandwidth_sports  population_reg_sports_share  students_reg_sports_share  \\\n",
       "0          269768.0                        22.37                      64.12   \n",
       "1          269768.0                        22.37                      64.12   \n",
       "2          269768.0                        22.37                      64.12   \n",
       "3          269768.0                        22.37                      64.12   \n",
       "4          269768.0                        22.37                      64.12   \n",
       "\n",
       "   apartment_build  apartment_fund_sqm  \n",
       "0          23587.0            230310.0  \n",
       "1          23587.0            230310.0  \n",
       "2          23587.0            230310.0  \n",
       "3          23587.0            230310.0  \n",
       "4          23587.0            230310.0  \n",
       "\n",
       "[5 rows x 391 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_merge = pd.merge(df_train, df_macro, how='left', on='timestamp')\n",
    "print(df_train_merge.shape)\n",
    "df_train_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's sort out our predicted value. Often in housing price datasets, there is a lot of skewness in the value to predict. Taking a log gives a more normal distribution. This tends to lead to less bias in the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4IAAAEpCAYAAADGTZxlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAgAADCMEAQAAhhGCAAAAw3wDIo43LxQ3ss4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1388637b2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = df_train_merge['price_doc']\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,3))\n",
    "\n",
    "target.plot(ax=axes[0], kind='hist', bins=100)\n",
    "np.log(target).plot(ax=axes[1], kind='hist', bins=100, color='green', secondary_y=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appears same thing is present in this data - so prediction variable will be log(house price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.log(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing input features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on just top of the dataset, we can see there are plenty of missing values in some columns. Let's see how bad the problem is. Since we have 390 features, we'll most likely be able to discard some features with many missing values.\n",
    "\n",
    "We can always come up with ways to add them in later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.63% of columns have more than 20% missing values.\n"
     ]
    }
   ],
   "source": [
    "percent_null = df_train_merge.isnull().mean(axis=0) > 0.20\n",
    "print(\"{:.2%} of columns have more than 20% missing values.\".format(np.mean(percent_null)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm happy to lose 5% of features and not have to worry about a proper imputation strategy. We'll also pull out the uninformative columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_clean = df_train_merge.loc[:, ~percent_null]\n",
    "df_train_clean = df_train_clean.drop(['id', 'price_doc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    191\n",
      "int64      157\n",
      "object      19\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['timestamp', 'product_type', 'sub_area', 'culture_objects_top_25',\n",
       "       'thermal_power_plant_raion', 'incineration_raion',\n",
       "       'oil_chemistry_raion', 'radiation_raion', 'railroad_terminal_raion',\n",
       "       'big_market_raion', 'nuclear_reactor_raion',\n",
       "       'detention_facility_raion', 'water_1line', 'big_road1_1line',\n",
       "       'railroad_1line', 'ecology', 'child_on_acc_pre_school',\n",
       "       'modern_education_share', 'old_education_build_share'], \n",
       "      dtype='<U25')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train_clean.dtypes.value_counts())\n",
    "np.array([c for c in df_train_clean.columns if df_train_clean[c].dtype == 'object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next question is how to handle the object data types. I'm going ot make the basic assumption that all floating and integer valued colums can be treated as one-dimensional values, so there is no need to dummy these.\n",
    "\n",
    "It's possible that you could do better processing on some of the object columns - for example, 'sub_area' could be replaced with a 2D coordinate vector of the area, so distance metrics make sense between each class. However, I'm just going to dummy every object variable except 'timestamp'. I'll replace 'timestamp' with a numeric value, since it makes sense to treat this as 1-dimensional and the distance is well-defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.313798\n",
      "1    1.314058\n",
      "2    1.314403\n",
      "3    1.314835\n",
      "4    1.315181\n",
      "Name: timestamp, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_train_clean['timestamp'] = pd.to_numeric(pd.to_datetime(df_train_clean['timestamp'])) / 1e18\n",
    "print(df_train_clean['timestamp'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30471, 536)\n"
     ]
    }
   ],
   "source": [
    "# This automatically only dummies object columns\n",
    "df_train_clean = pd.get_dummies(df_train_clean).astype(np.float64)\n",
    "print(df_train_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_train_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 536 features and 30,471 total observation at this point. Since the number of features is low, the challenge is going to be finding a model with high capacity, rather than necessarily adding lots of regularization at this stage. Not worried about overfitting yet.\n",
    "\n",
    "Let's prepare the data for learning. To do this, we'll follow basic steps:\n",
    "\n",
    "1. Make a train/test split\n",
    "2. Impute values for the missing values - we will replace with the mean\n",
    "3. Scale every value by mean and standard deviation.\n",
    "\n",
    "We are going to use the imputer class from sklearn - this doesn't support different imputing methods for different coumns. Ideally for the [0,1] values we converted from strings, you would use the mode, but for the continuous you would use the mean. You could write a class to implement this, but again this is just a rough and ready approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24111955,  1.17119378,  3.08833722, ...,  1.68270601,\n",
       "        -0.90219755, -0.34434811],\n",
       "       [ 1.04279123,  0.58325276,  2.89938436, ..., -0.59428087,\n",
       "         1.1084047 , -0.34434811],\n",
       "       [ 0.65732148, -0.10267843, -0.87967294, ..., -0.59428087,\n",
       "         1.1084047 , -0.34434811],\n",
       "       ..., \n",
       "       [ 0.09097747,  0.63224784,  1.38776144, ..., -0.59428087,\n",
       "         1.1084047 , -0.34434811],\n",
       "       [-0.05431498,  0.24028716,  1.00985571, ...,  1.68270601,\n",
       "        -0.90219755, -0.34434811],\n",
       "       [ 0.31632901, -0.42114648,  0.63194998, ..., -0.59428087,\n",
       "         1.1084047 , -0.34434811]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Make a pipeline that transforms X\n",
    "pipeline = make_pipeline(Imputer(), StandardScaler())\n",
    "pipeline.fit(X_train)\n",
    "pipeline.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want a single real-valued metric for comparing models and implementations. Kaggle tells us the metric - RMSLE (Root Mean Squared Log Error).\n",
    "\n",
    "For convenience, will take exponential in this function since the model is working in log(house price)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle_exp(y_true_log, y_pred_log):\n",
    "    y_true = np.exp(y_true_log)\n",
    "    y_pred = np.exp(y_pred_log)\n",
    "    return np.sqrt(np.mean(np.power(np.log(y_true + 1) - np.log(y_pred + 1), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_model(model, pipe):\n",
    "    train_error = rmsle_exp(y_train, model.predict(pipe.transform(X_train)))\n",
    "    test_error = rmsle_exp(y_test, model.predict(pipe.transform(X_test)))\n",
    "    return train_error, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything we need for making predictions. Let's fit a basic linear model. Expect to underfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression(fit_intercept=True)\n",
    "lr.fit(pipeline.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 0.5126, Test error: 0.5075\n"
     ]
    }
   ],
   "source": [
    "print(\"Train error: {:.4f}, Test error: {:.4f}\".format(*score_model(lr, pipeline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is close to the benchmark level for the competition.\n",
    "\n",
    "Let's look at a few more \"out-of-box\" methods - SVR, Random Forests, and XGBoost.\n",
    "\n",
    "SVR allows for nice non-linearities if you use the Guassian kernel. The downside is it takes a long time to fit the data. You should also run cross=validation on the parameters C (the regularization parameters) and what sklearn calls 'gamma', the standard deviation of the kernel. \n",
    "\n",
    "Note - due to high runtime, maybe don't run SVR, it performs worse than random forests but better than linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.svm import SVR\\n\\nsvr = SVR()\\nsvr.fit(pipeline.transform(X_train), y_train)\\n\\nprint(\"Train error: {:.4f}, Test error: {:.4f}\".format(*score_model(svr, pipeline)))\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "svr.fit(pipeline.transform(X_train), y_train)\n",
    "\n",
    "print(\"Train error: {:.4f}, Test error: {:.4f}\".format(*score_model(svr, pipeline)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up are tree models - will use same n_estimators. Random forests will overfit until you set min_samples_leaf to a reasonable value, so pick 50 arbitrarily. Again, cross validation can help determine better than default setting for this and many other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 0.4339, Test error: 0.4616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=100, min_samples_leaf=50, n_jobs=-1)\n",
    "rfr.fit(pipeline.transform(X_train), y_train)\n",
    "\n",
    "print(\"Train error: {:.4f}, Test error: {:.4f}\".format(*score_model(rfr, pipeline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in just base implementations, XGBOost is (very slightly) the winner.\n",
    "\n",
    "There are many steps you can take to improve these models. For example:\n",
    "1. Engineer better features from the data.\n",
    "2. Use some of the features we threw out at the start.\n",
    "3. Cross-validate on the many parameters the more complicated models have.\n",
    "4. Try a model we haven't used yet (deep network, polynomial features in regression)\n",
    "\n",
    "Basic code submission below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=-1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit the model on everything, including our held-out test set\n",
    "pipeline.fit(X)\n",
    "rfr.fit(pipeline.transform(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30474</td>\n",
       "      <td>5.250097e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30475</td>\n",
       "      <td>8.153513e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30476</td>\n",
       "      <td>5.672289e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30477</td>\n",
       "      <td>6.264026e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30478</td>\n",
       "      <td>5.250644e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     price_doc\n",
       "0  30474  5.250097e+06\n",
       "1  30475  8.153513e+06\n",
       "2  30476  5.672289e+06\n",
       "3  30477  6.264026e+06\n",
       "4  30478  5.250644e+06"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the same steps to process the test data\n",
    "df_test_merge = pd.merge(df_test, df_macro, how='left', on='timestamp')\n",
    "df_test_merge['timestamp'] = pd.to_numeric(pd.to_datetime(df_test_merge['timestamp'])) / 1e18\n",
    "df_test_merge = pd.get_dummies(df_test_merge).astype(np.float64)\n",
    "\n",
    "# Make sure it's in the same format as the training data\n",
    "df_test_compare = pd.DataFrame(columns=df_train_clean.columns)\n",
    "for column in df_test_compare.columns:\n",
    "    if column in df_test_merge.columns:\n",
    "        df_test_compare[column] = df_test_merge[column]\n",
    "    else:\n",
    "        df_test_compare[column] = np.nan\n",
    "\n",
    "# Make the predictions\n",
    "predictions = np.exp(rfr.predict(pipeline.transform(df_test_compare)))\n",
    "\n",
    "# And put prediction in a dataframe\n",
    "df_predictions = pd.DataFrame()\n",
    "df_predictions['id'] = df_test['id']\n",
    "df_predictions['price_doc'] = predictions\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now output to CSV\n",
    "df_predictions.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
